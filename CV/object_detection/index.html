<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://abari11.github.io/CV/object_detection/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Object detection - abari-dodo-mamane</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Object detection";
        var mkdocs_page_input_path = "CV\\object_detection.md";
        var mkdocs_page_url = "/CV/object_detection/";
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> abari-dodo-mamane
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Artificial Intelligence</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../AI/ai_def/">AI Meaning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">AI and Ethics</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/exp_inter/">Interpretability & Explainability</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Machine Learning</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Introduction</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Deep Learning</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/intro/">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/dl_model/">Deep Learning Models</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/optim_ml/">Optimization in Machine Learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/loss_func/">Loss functions</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/training/">Training a deep learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/train_val_test/">Train, validation, test dataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/act_func/">Activation functions</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/hyper_par_optim/">Hyper-parameters optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/learning_ml/">Learning in machine learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/training_pb/">Avoid recurrent training problems</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/backpropagation_algo/">Backpropagation algorithm</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/par_init/">Parameters initialization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Automatic Differentiation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/dl_framework/">Deep Learning framework</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Vanishing and Exploding gradients</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/MLOPS/">MLOPS</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/exp_inter/">Explainability and interpretability in machine learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Machine learning project</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Computer vision</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../..">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Digital Image Processing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Image Classification</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Object detection</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#1-quest-ce-que-la-detection-des-objets">1. Qu'est-ce que la detection des objets</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-interets-et-applications">2. Interets et Applications</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-les-algorithmes-de-la-detection-des-objets">3. Les algorithmes de la detection des objets</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#31-algorithm-performance-evaluation">3.1 Algorithm performance evaluation</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#32-benchmark-datasets-for-object-detection">3.2 Benchmark Datasets for object detection</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-detection-avec-yolo">4. Detection avec YOLO</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#41-introduction">4.1 Introduction</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#42-concepts-a-comprendre">4.2 concepts Ã  comprendre</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#43-versions-des-yolo">4.3 Versions des YOLO</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Object Segmentation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Object Tracking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Image Captionning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Video Understanding</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Pose estimation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Programming Lang</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Python</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">C++</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI for Africa</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Data governance</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Other</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Git</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">abari-dodo-mamane</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Computer vision &raquo;</li>
      <li>Object detection</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <p><link rel="stylesheet" href="css/style.css"></p>
<h1 id="detection-des-objets">Detection des objets</h1>
<h2 id="1-quest-ce-que-la-detection-des-objets">1. Qu'est-ce que la detection des objets</h2>
<p>La dÃ©tection des objets est une tÃ¢che de la vision par ordinateur qui consiste Ã  identifier et localiser un ensemble d'objets prÃ©difinis dans une image.</p>
<p>Le but de la detection des objets est de determiner, Ã©tant donnÃ©e une image la presence des objets appartenant Ã  un ensemble de classes prÃ©definies, dans le cas Ã©cheant de donner la localisation et la categorie de chaque objet present dans l'image. Pour localiser un objet on peut utiliser des bounding boxes, le centre de l'objet etc.</p>
<p>Les techniques d'intelligence artificielle, plus particuliÃ¨rement les rÃ©seaux de neurones, ont permis des avancÃ©es considerables dans le domaine de la dÃ©tection des objets.
Les objets qui font l'interet d'une detection sont des objets tres structurÃ©s (voitures, avions, chaises etc) ou articulÃ©s tels que les humains, les animaux etc. On s'interesse trÃ¨s rarement aux objets non structurÃ©s tels que le ciel, les nuages, grass etc.</p>
<h2 id="2-interets-et-applications">2. Interets et Applications</h2>
<p>La detection des objets est essentiel pour des tÃ¢ches complexes telles que la segmentation, la comprehension des scÃ¨nes, le suivi d'objets, image captionning, detection d'Ã©vÃ©nements, et reconnaissance des activitÃ©s.
Les applicatons oÃ¹ la detection des objets est utilisÃ©e sont nombreuses. On peut retenir:</p>
<ul>
<li>Robot vision</li>
<li>Electromenager</li>
<li>SecuritÃ© et surveillance</li>
<li>Autonomous driving</li>
<li>human computer interaction</li>
<li>content based image retrieval</li>
<li>Intelligent video surveillance</li>
<li>Augmented Reality</li>
</ul>
<h2 id="3-les-algorithmes-de-la-detection-des-objets">3. Les algorithmes de la detection des objets</h2>
<h3 id="31-algorithm-performance-evaluation">3.1 Algorithm performance evaluation</h3>
<p>Le but de la detection des objets est de mettre en place des algorithmes qui sont d'une grande exactitude (high accurate) et d'une grande effacitÃ© (high efficiency). high accurate car les objets doit Ãªtre reconnu et localisÃ© avec une grande precision dans des images ou vidÃ©os, avoir la capacitÃ© Ã  differencier plusieurs categories d'objets. High efficiency parce que la detection doit Ãªtre faite en temps rÃ©el avec moins de ressources (temps, memoire, puissance de calcul).
Les metriques d'evaluation de performance utilisÃ©es :</p>
<h4 id="32-benchmark-datasets-for-object-detection">3.2 Benchmark Datasets for object detection</h4>
<p>Les datasets jouent un rÃ´le important dans l'evaluation de la perfomance d'un algorithm de detection d'objets. Elles permettent de comparer et de mesurer les performances des algorithmes. PLusieurs benchmark datasets existent pour la detection des objets. Parmi lesquels on a:
- ImageNet
- PASCAL VOC
- MS COCO DATASET
Le processus de crÃ©ation de ces datasets est :
Identifier les classes d'objets qui doivent constituer la dataset
Collecter sur Internet les images
Annoter les images collectÃ©es suivant un format bien choisie (crowdsourcing strategies)</p>
<h2 id="4-detection-avec-yolo">4. Detection avec YOLO</h2>
<h3 id="41-introduction">4.1 Introduction</h3>
<h3 id="42-concepts-a-comprendre">4.2 concepts Ã  comprendre</h3>
<h3 id="43-versions-des-yolo">4.3 Versions des YOLO</h3>
<p>Plusieurs versions de YOLO existent. Voici une chronologie des amÃ©liorations:</p>
<p>YOLO V1:
Utilise GoogleNet pour l'extraction des features
Avantages: One-shot detection mechanism, real-time
Inconvenients : DifficultÃ©s Ã  detecter les petits objets et les objets avec un aspect ratio (w/h) inhabituel, erreur de localisation comparer Ã  certains algorithme de detection.</p>
<ul>
<li>
<p>YOLO V2:</p>
<ul>
<li>AmÃ©liorations:
    Utilisation des anchors boxes pour la localisation des objets</li>
<li>Batch normalization dans les cnn</li>
<li>High resolution classifier</li>
<li>Utilise Darknet19 comme backbone</li>
<li>Inconvenients</li>
</ul>
</li>
<li>
<p>YOLO V3:</p>
<ul>
<li>AmÃ©liorations<ul>
<li>Utilise Darknet53</li>
<li>binary cross entropy in loss calculations</li>
<li>Use of logistic regression in predicting the "objectness score" for each bounding box</li>
<li>Feature extraction at three different scales inspired by FPN</li>
</ul>
</li>
<li>Inconvenient: Amelioration de l'accuracy a eu impact sur inference speed</li>
</ul>
</li>
<li>
<p>YOLO V3:</p>
<ul>
<li>AmÃ©liorations:</li>
<li>Utilise CSPDarknet53
Use of Mish and Leaky ReLU as Activation function
Adoption of a path aggregation network in place of FPN
Use of Spatial Pyramid Pooling as a plug-in module</li>
</ul>
</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../.." class="btn btn-neutral float-left" title="Image Classification"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../.." class="btn btn-neutral float-right" title="Object Segmentation">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../.." style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../.." style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
