<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://abari11.github.io/CV/object_detection/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Object detection - abari-dodo-mamane</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Object detection";
        var mkdocs_page_input_path = "CV\\object_detection.md";
        var mkdocs_page_url = "/CV/object_detection/";
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> abari-dodo-mamane
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Artificial Intelligence</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../AI/ai_def/">AI Meaning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">AI and Ethics</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/exp_inter/">Interpretability & Explainability</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Machine Learning</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Introduction</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Deep Learning</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/intro/">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/dl_model/">Deep Learning Models</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/optim_ml/">Optimization in Machine Learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/loss_func/">Loss functions</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/training/">Training a deep learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/train_val_test/">Train, validation, test dataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/act_func/">Activation functions</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/hyper_par_optim/">Hyper-parameters optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/learning_ml/">Learning in machine learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/training_pb/">Avoid recurrent training problems</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/backpropagation_algo/">Backpropagation algorithm</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/par_init/">Parameters initialization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Automatic Differentiation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/dl_framework/">Deep Learning framework</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Vanishing and Exploding gradients</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/MLOPS/">MLOPS</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../DL/exp_inter/">Explainability and interpretability in machine learning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Machine learning project</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Computer vision</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../..">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Digital Image Processing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Image Classification</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Object detection</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#1-quest-ce-que-la-detection-des-objets">1. Qu'est-ce que la detection des objets</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-interets-et-applications">2. Interets et Applications</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-les-algorithmes-de-la-detection-des-objets">3. Les algorithmes de la detection des objets</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#31-algorithm-performance-evaluation">3.1 Algorithm performance evaluation</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#32-benchmark-datasets-for-object-detection">3.2 Benchmark Datasets for object detection</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-detection-avec-yolo">4. Detection avec YOLO</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#41-introduction">4.1 Introduction</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#42-concepts-a-comprendre">4.2 concepts à comprendre</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#43-versions-des-yolo">4.3 Versions des YOLO</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Object Segmentation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Object Tracking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Image Captionning</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Video Understanding</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Pose estimation</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Programming Lang</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Python</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../..">C++</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">AI for Africa</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Data governance</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Other</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../..">Git</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">abari-dodo-mamane</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Computer vision &raquo;</li>
      <li>Object detection</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <p><link rel="stylesheet" href="css/style.css"></p>
<h1 id="detection-des-objets">Detection des objets</h1>
<h2 id="1-quest-ce-que-la-detection-des-objets">1. Qu'est-ce que la detection des objets</h2>
<p>La détection des objets est une tâche de la vision par ordinateur qui consiste à identifier et localiser un ensemble d'objets prédifinis dans une image.</p>
<p>Le but de la detection des objets est de determiner, étant donnée une image la presence des objets appartenant à un ensemble de classes prédefinies, dans le cas écheant de donner la localisation et la categorie de chaque objet present dans l'image. Pour localiser un objet on peut utiliser des bounding boxes, le centre de l'objet etc.</p>
<p>Les techniques d'intelligence artificielle, plus particulièrement les réseaux de neurones, ont permis des avancées considerables dans le domaine de la détection des objets.
Les objets qui font l'interet d'une detection sont des objets tres structurés (voitures, avions, chaises etc) ou articulés tels que les humains, les animaux etc. On s'interesse très rarement aux objets non structurés tels que le ciel, les nuages, grass etc.</p>
<h2 id="2-interets-et-applications">2. Interets et Applications</h2>
<p>La detection des objets est essentiel pour des tâches complexes telles que la segmentation, la comprehension des scènes, le suivi d'objets, image captionning, detection d'événements, et reconnaissance des activités.
Les applicatons où la detection des objets est utilisée sont nombreuses. On peut retenir:</p>
<ul>
<li>Robot vision</li>
<li>Electromenager</li>
<li>Securité et surveillance</li>
<li>Autonomous driving</li>
<li>human computer interaction</li>
<li>content based image retrieval</li>
<li>Intelligent video surveillance</li>
<li>Augmented Reality</li>
</ul>
<h2 id="3-les-algorithmes-de-la-detection-des-objets">3. Les algorithmes de la detection des objets</h2>
<h3 id="31-algorithm-performance-evaluation">3.1 Algorithm performance evaluation</h3>
<p>Le but de la detection des objets est de mettre en place des algorithmes qui sont d'une grande exactitude (high accurate) et d'une grande effacité (high efficiency). high accurate car les objets doit être reconnu et localisé avec une grande precision dans des images ou vidéos, avoir la capacité à differencier plusieurs categories d'objets. High efficiency parce que la detection doit être faite en temps réel avec moins de ressources (temps, memoire, puissance de calcul).
Les metriques d'evaluation de performance utilisées :</p>
<h4 id="32-benchmark-datasets-for-object-detection">3.2 Benchmark Datasets for object detection</h4>
<p>Les datasets jouent un rôle important dans l'evaluation de la perfomance d'un algorithm de detection d'objets. Elles permettent de comparer et de mesurer les performances des algorithmes. PLusieurs benchmark datasets existent pour la detection des objets. Parmi lesquels on a:
- ImageNet
- PASCAL VOC
- MS COCO DATASET
Le processus de création de ces datasets est :
Identifier les classes d'objets qui doivent constituer la dataset
Collecter sur Internet les images
Annoter les images collectées suivant un format bien choisie (crowdsourcing strategies)</p>
<h2 id="4-detection-avec-yolo">4. Detection avec YOLO</h2>
<h3 id="41-introduction">4.1 Introduction</h3>
<h3 id="42-concepts-a-comprendre">4.2 concepts à comprendre</h3>
<h3 id="43-versions-des-yolo">4.3 Versions des YOLO</h3>
<p>Plusieurs versions de YOLO existent. Voici une chronologie des améliorations:</p>
<p>YOLO V1:
Utilise GoogleNet pour l'extraction des features
Avantages: One-shot detection mechanism, real-time
Inconvenients : Difficultés à detecter les petits objets et les objets avec un aspect ratio (w/h) inhabituel, erreur de localisation comparer à certains algorithme de detection.</p>
<ul>
<li>
<p>YOLO V2:</p>
<ul>
<li>Améliorations:
    Utilisation des anchors boxes pour la localisation des objets</li>
<li>Batch normalization dans les cnn</li>
<li>High resolution classifier</li>
<li>Utilise Darknet19 comme backbone</li>
<li>Inconvenients</li>
</ul>
</li>
<li>
<p>YOLO V3:</p>
<ul>
<li>Améliorations<ul>
<li>Utilise Darknet53</li>
<li>binary cross entropy in loss calculations</li>
<li>Use of logistic regression in predicting the "objectness score" for each bounding box</li>
<li>Feature extraction at three different scales inspired by FPN</li>
</ul>
</li>
<li>Inconvenient: Amelioration de l'accuracy a eu impact sur inference speed</li>
</ul>
</li>
<li>
<p>YOLO V3:</p>
<ul>
<li>Améliorations:</li>
<li>Utilise CSPDarknet53
Use of Mish and Leaky ReLU as Activation function
Adoption of a path aggregation network in place of FPN
Use of Spatial Pyramid Pooling as a plug-in module</li>
</ul>
</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../.." class="btn btn-neutral float-left" title="Image Classification"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../.." class="btn btn-neutral float-right" title="Object Segmentation">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../.." style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../.." style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
